{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7299ad77-713b-4338-aa6b-ca1a98a4d03c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### build_embeddings.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6ed368-f713-4877-9907-288fb8c457a7",
   "metadata": {},
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from utils_facenet import embed_from_path\n",
    "\n",
    "DATA_DIR = \"data/train\"\n",
    "\n",
    "embeddings = []\n",
    "labels = []\n",
    "\n",
    "for person in os.listdir(DATA_DIR):\n",
    "    person_dir = os.path.join(DATA_DIR, person)\n",
    "    if not os.path.isdir(person_dir):\n",
    "        continue\n",
    "\n",
    "    print(f\"Proses folder: {person}\")\n",
    "\n",
    "    for img_name in os.listdir(person_dir):\n",
    "        img_path = os.path.join(person_dir, img_name)\n",
    "        print(\"  →\", img_path)\n",
    "\n",
    "        emb = embed_from_path(img_path)\n",
    "        if emb is None:\n",
    "            print(\"  [X] Wajah tidak terdeteksi. Dilewati.\")\n",
    "            continue\n",
    "\n",
    "        embeddings.append(emb)\n",
    "        labels.append(person)\n",
    "\n",
    "embeddings = np.array(embeddings)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(\"\\nJumlah embedding:\", len(embeddings))\n",
    "\n",
    "np.savez(\"embeddings.npz\", embeddings=embeddings, labels=labels)\n",
    "print(\"embeddings.npz berhasil disimpan!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f673a47c-85f3-4bf5-bc21-fba1040018d8",
   "metadata": {},
   "source": [
    "#### Analisis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd5bd18-d87d-4bd3-adf3-f3e0bec10dd0",
   "metadata": {},
   "source": [
    "Script build_embeddings.py berfungsi untuk memproses dataset wajah di folder data/train dan menghasilkan file embeddings.npz yang berisi vektor embedding serta label masing-masing gambar. Program memulai dengan membaca setiap folder yang merepresentasikan identitas seseorang, lalu masuk ke setiap file gambar di dalamnya. Untuk setiap gambar, script memanggil fungsi embed_from_path() yang berasal dari utils_facenet, yang bertugas mendeteksi wajah dan menghasilkan embedding numerik (biasanya panjang 128 atau 512 tergantung model). Jika wajah tidak terdeteksi, gambar dilewati agar hasil dataset tetap bersih. Embedding yang valid dimasukkan ke list embeddings, dan nama folder (identitas orang) dimasukkan ke list labels. Setelah semua folder selesai diproses, kedua list tersebut diubah menjadi array NumPy dan disimpan ke satu file embeddings.npz, sehingga memudahkan dipakai pada model lain seperti KNN, SVM, atau sistem verifikasi wajah. Struktur ini memastikan dataset embedding konsisten, mudah di-load, dan efisien digunakan pada tahap training maupun prediksi berikutnya."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98545f3-0544-43e1-aa11-ea8c3a0efe77",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### convert_npz_to_npy.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a908283-944b-4e9b-9600-dbab3c0ef03f",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.load(\"embeddings.npz\")\n",
    "\n",
    "X = data[\"embeddings\"]\n",
    "y = data[\"labels\"]\n",
    "\n",
    "np.save(\"X_train.npy\", X)\n",
    "np.save(\"y_train.npy\", y)\n",
    "\n",
    "print(\"Berhasil membuat X_train.npy dan y_train.npy\")\n",
    "print(\"Shape X:\", X.shape)\n",
    "print(\"Jumlah label:\", len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c185e63e-f275-40b7-913e-648e5e7ab2f5",
   "metadata": {},
   "source": [
    "#### Analisis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd0a075-c49a-438a-9298-99d10d512fe8",
   "metadata": {},
   "source": [
    "Script convert_npz_to_npy.py berfungsi untuk mengambil data embedding wajah yang sebelumnya disimpan dalam satu file embeddings.npz dan memecahnya menjadi dua file terpisah, yaitu X_train.npy dan y_train.npy. Saat file embeddings.npz dibuka menggunakan np.load, script mengambil dua array utama: embeddings sebagai fitur (X) dan labels sebagai identitas atau target (y). Setelah itu, masing-masing array disimpan kembali ke format .npy, yang lebih sederhana dan cepat diakses ketika digunakan pada model machine learning seperti KNN atau SVM. File X_train.npy akan berisi seluruh vektor embedding numerik, sementara y_train.npy menyimpan label orang untuk setiap embedding. Terakhir, script menampilkan ukuran X dan jumlah label sebagai verifikasi bahwa data berhasil diekstrak dengan benar. Proses ini memastikan dataset lebih modular, lebih mudah di-load secara terpisah, dan siap dipakai untuk tahap training model pengenalan wajah."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334a73c2-0abb-4126-bd8f-a9cafacb2b57",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### evaluate.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a358479-92ab-49ff-bd53-786e7147b50f",
   "metadata": {},
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "from utils_facenet import embed_from_path\n",
    "\n",
    "VAL_DIR = \"data/val\"\n",
    "clf = joblib.load(\"svm_model.pkl\")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for person in os.listdir(VAL_DIR):\n",
    "    person_dir = os.path.join(VAL_DIR, person)\n",
    "    if not os.path.isdir(person_dir):\n",
    "        continue\n",
    "\n",
    "    print(f\"Testing folder: {person}\")\n",
    "\n",
    "    for img_name in os.listdir(person_dir):\n",
    "        img_path = os.path.join(person_dir, img_name)\n",
    "\n",
    "        emb = embed_from_path(img_path)\n",
    "        if emb is None:\n",
    "            print(f\"  [X] Gagal deteksi wajah: {img_name}\")\n",
    "            continue\n",
    "\n",
    "        pred = clf.predict([emb])[0]\n",
    "        print(f\"  → {img_name} | Prediksi: {pred} | Label benar: {person}\")\n",
    "\n",
    "        if pred == person:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "\n",
    "print(\"\\nTotal data:\", total)\n",
    "print(\"Benar:\", correct)\n",
    "print(\"Akurasi:\", correct / total if total > 0 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48c3fac-5d42-4eca-8a9c-b23505fbfcd2",
   "metadata": {},
   "source": [
    "#### Analisis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83931b7c-20d1-49bd-b019-9507f14182f9",
   "metadata": {},
   "source": [
    "Script evaluate.py digunakan untuk menghitung akurasi model pengenalan wajah berbasis SVM menggunakan dataset validasi yang berada di folder data/val. Program memulai dengan memuat model SVM yang telah dilatih sebelumnya melalui file svm_model.pkl. Kemudian, untuk setiap folder di dalam data/val—yang masing-masing mewakili identitas seseorang—script membaca seluruh gambar di dalamnya. Setiap gambar diproses menggunakan fungsi embed_from_path() untuk menghasilkan embedding wajah; jika wajah gagal terdeteksi, gambar dilewati agar tidak memengaruhi hasil evaluasi. Setelah embedding berhasil dibuat, model SVM melakukan prediksi identitas dan hasilnya dibandingkan dengan nama folder sebagai label ground truth. Program juga mencetak hasil prediksi setiap gambar sehingga memudahkan debugging. Setiap prediksi yang benar akan menambah hitungan correct, sedangkan total gambar valid akan menambah total. Di akhir proses, script menampilkan total data yang diuji, jumlah prediksi benar, dan nilai akurasi keseluruhan. Dengan cara ini, pengguna dapat menilai seberapa baik model SVM mengenali wajah pada data baru yang tidak digunakan saat training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f380b5-a857-46b6-bfdb-119f6e9fb2f4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f258ff7b-7753-4b9f-bd50-b1b9e7612f8d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### predict_knn.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb19e486-5108-41d2-85e1-75b22f8db7ab",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "from utils_facenet import embed_from_path\n",
    "import sys\n",
    "\n",
    "MODEL_PATH = \"knn_model.pkl\"\n",
    "\n",
    "#Load model KNN\n",
    "knn = joblib.load(MODEL_PATH)\n",
    "\n",
    "def predict_image(img_path):\n",
    "    emb = embed_from_path(img_path)\n",
    "    if emb is None:\n",
    "        print(\"❌ Wajah tidak terdeteksi.\")\n",
    "        return\n",
    "    \n",
    "    emb = emb.reshape(1, -1)  # bentuk menjadi (1, 512)\n",
    "    pred = knn.predict(emb)[0]\n",
    "\n",
    "    # hitung jarak untuk confidence\n",
    "    dist, i# train_knn.py\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import joblib\n",
    "\n",
    "#======================\n",
    "#Load dataset dari embeddings.npz\n",
    "#======================\n",
    "data = np.load(\"embeddings.npz\")\n",
    "\n",
    "X = data[\"embeddings\"]   # ← sesuai key\n",
    "y = data[\"labels\"]       # ← sesuai key\n",
    "\n",
    "print(\"Shape X:\", X.shape)\n",
    "print(\"Shape y:\", y.shape)\n",
    "\n",
    "#======================\n",
    "#Training KNN\n",
    "#======================\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X, y)\n",
    "\n",
    "#======================\n",
    "#Simpan model\n",
    "#======================\n",
    "joblib.dump(knn, \"knn_model.pkl\")\n",
    "print(\"Model KNN berhasil disimpan! → knn_model.pkl\")dx = knn.kneighbors(emb, n_neighbors=1, return_distance=True)\n",
    "    conf = 1 / (1 + dist[0][0])\n",
    "\n",
    "    print(\"\\nMemprediksi gambar:\", img_path)\n",
    "    print(\"Prediksi:\", pred)\n",
    "    print(\"Confidence:\", round(conf, 3))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) < 2:\n",
    "        print(\"Usage: python predict_knn.py <path_gambar>\")\n",
    "    else:\n",
    "        predict_image(sys.argv[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfb6bd3-2f4a-47d1-868f-82ab5d813309",
   "metadata": {},
   "source": [
    "#### Analisis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5070bb-eb3d-42a7-9a44-f5c998302361",
   "metadata": {},
   "source": [
    "Script ini dirancang untuk melakukan prediksi identitas wajah menggunakan model KNN yang telah dilatih sebelumnya dan disimpan dalam file knn_model.pkl. Pertama, program memuat model KNN menggunakan joblib.load, kemudian mendefinisikan fungsi predict_image() yang menerima path gambar sebagai input. Di dalam fungsi tersebut, gambar diubah menjadi embedding wajah menggunakan embed_from_path(). Jika wajah tidak terdeteksi, proses dihentikan agar prediksi tidak salah. Embedding kemudian di-reshape menjadi bentuk dua dimensi (1, 512) karena model KNN hanya menerima input dalam bentuk batch, bukan satu dimensi tunggal. Setelah itu, model melakukan prediksi label identitas menggunakan knn.predict(). Untuk memberikan informasi tingkat keyakinan (confidence), script menghitung jarak terdekat ke tetangga terdekat KNN dengan knn.kneighbors(). Nilai confidence dihitung menggunakan rumus sederhana 1 / (1 + distance), di mana semakin kecil jarak, semakin tinggi confidence. Program juga menampilkan prediksi, confidence, dan nama file gambar untuk memudahkan debugging. Pada bagian main, script menerima path gambar melalui argumen command-line dan menjalankan prediksi hanya jika argumen diberikan. Dengan struktur seperti ini, script sangat praktis digunakan untuk pengujian cepat terhadap satu gambar tanpa perlu membuat pipeline tambahan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122b594d-247f-486a-9e02-011b4626495f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### train_classifier.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bf0987-ccfa-4f8e-9517-511e88a04912",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "\n",
    "#Load embeddings\n",
    "data = np.load(\"embeddings.npz\")\n",
    "X = data[\"embeddings\"]   # embedding 512-dim\n",
    "y = data[\"labels\"]        # nama orangnya\n",
    "\n",
    "print(\"Shape X:\", X.shape)\n",
    "print(\"Labels:\", y)\n",
    "\n",
    "#Create classifier\n",
    "clf = SVC(kernel=\"linear\", probability=True)\n",
    "\n",
    "#Train\n",
    "print(\"Training classifier...\")\n",
    "clf.fit(X, y)\n",
    "\n",
    "#Save model\n",
    "joblib.dump(clf, \"svm_model.pkl\")\n",
    "print(\"Model SVM berhasil disimpan sebagai svm_model.pkl!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82272f3-372d-4ec4-a010-fb045dcab883",
   "metadata": {},
   "source": [
    "#### Analisis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6902762f-d4aa-41b7-a18b-f0f30ccbf254",
   "metadata": {},
   "source": [
    "Script train_classifier.py berfungsi untuk melatih model klasifikasi wajah menggunakan algoritma Support Vector Machine (SVM) berbasis kernel linear. Program dimulai dengan memuat file embeddings.npz, yang berisi dua array penting: embeddings (X) sebagai fitur wajah berdimensi tinggi dan labels (y) sebagai identitas orang dari setiap embedding. Setelah menampilkan ukuran data untuk verifikasi, script membuat model SVM dengan parameter kernel=\"linear\" yang sangat cocok untuk data embedding wajah karena sifat ruang vektor yang sudah relatif terpisah secara linear. Opsi probability=True ditambahkan agar model mampu memberikan output probabilitas prediksi saat digunakan nanti. Proses training kemudian dijalankan menggunakan clf.fit(X, y), di mana model mempelajari hubungan antara embedding wajah dan identitas aslinya. Setelah pelatihan selesai, model disimpan ke dalam file svm_model.pkl melalui joblib.dump, sehingga dapat digunakan kembali di script lain seperti evaluasi atau prediksi real-time tanpa harus melatih ulang. Dengan struktur yang sederhana dan efisien, script ini menyediakan proses training yang jelas, mudah dipahami, dan langsung siap digunakan dalam sistem face recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceb05bb-af01-4ae1-b795-e1860514c77d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### train_knn.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f703ac9-7a8c-4c9a-a067-599f613f72fd",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import joblib\n",
    "\n",
    "#======================\n",
    "#Load dataset dari embeddings.npz\n",
    "#======================\n",
    "data = np.load(\"embeddings.npz\")\n",
    "\n",
    "X = data[\"embeddings\"]   # ← sesuai key\n",
    "y = data[\"labels\"]       # ← sesuai key\n",
    "\n",
    "print(\"Shape X:\", X.shape)\n",
    "print(\"Shape y:\", y.shape)\n",
    "\n",
    "#======================\n",
    "#Training KNN\n",
    "#======================\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X, y)\n",
    "\n",
    "#======================\n",
    "#Simpan model\n",
    "#======================\n",
    "joblib.dump(knn, \"knn_model.pkl\")\n",
    "print(\"Model KNN berhasil disimpan! → knn_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e9eadc-f3d0-42c3-8cca-bacbd2902839",
   "metadata": {},
   "source": [
    "#### Analisis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9617e0-4e05-440b-bf87-c71144f43358",
   "metadata": {},
   "source": [
    "Script train_knn.py digunakan untuk melatih model klasifikasi wajah berbasis K-Nearest Neighbors (KNN) menggunakan embedding wajah yang tersimpan dalam file embeddings.npz. Program diawali dengan memuat dataset embedding dan label, yang masing-masing mewakili vektor fitur wajah berdimensi tinggi serta identitas orangnya. Informasi shape ditampilkan untuk memastikan data telah terbaca dengan benar. Kemudian, script membuat model KNN dengan parameter n_neighbors=1, yang berarti setiap prediksi akan bergantung pada jarak embedding terdekat tunggal dalam ruang vektor. Penggunaan K=1 sangat umum dalam face recognition karena embedding FaceNet cenderung terdistribusi dengan baik sehingga jarak terdekat biasanya cukup untuk memisahkan identitas. Model KNN lalu dilatih menggunakan .fit(X, y), di mana proses ini sebenarnya hanya menyimpan data tanpa membangun hyperplane, karena KNN merupakan lazy learner. Setelah training selesai, model disimpan sebagai knn_model.pkl menggunakan joblib agar dapat dipakai di script lain, seperti predict_knn.py. Dengan struktur sederhana namun efektif, script ini memungkinkan pembuatan model face recognition berbasis jarak yang cepat, mudah, dan sangat cocok untuk sistem real-time atau skala kecil–menengah."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73e0dd3-4af3-4c61-9590-821e62f6f3c5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### utils_facenet.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d04775-091c-4cd5-8951-71a1b27299c6",
   "metadata": {},
   "source": [
    "import torch, numpy as np, cv2\n",
    "from PIL import Image\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#Detector & aligner\n",
    "mtcnn = MTCNN(image_size=160, margin=20, post_process=True, device=device)\n",
    "\n",
    "#Embedder (512-dim)\n",
    "embedder = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
    "\n",
    "def read_img_bgr(path):\n",
    "    img = cv2.imread(path)  # BGR\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Gagal baca: {path}\")\n",
    "    return img\n",
    "\n",
    "def bgr_to_pil(img_bgr):\n",
    "    return Image.fromarray(cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "@torch.no_grad()\n",
    "def face_align(img_bgr):\n",
    "    \"\"\"Return aligned face as PIL.Image (160x160) or None if not found.\"\"\"\n",
    "    pil = bgr_to_pil(img_bgr)\n",
    "    aligned = mtcnn(pil)  # tensor [3,160,160] atau None\n",
    "    return aligned\n",
    "\n",
    "@torch.no_grad()\n",
    "def embed_face_tensor(face_tensor):\n",
    "    if face_tensor is None:\n",
    "        return None\n",
    "    face_tensor = face_tensor.unsqueeze(0).to(device)\n",
    "    emb = embedder(face_tensor)\n",
    "    return emb.squeeze(0).cpu().numpy()\n",
    "\n",
    "@torch.no_grad()\n",
    "def embed_from_path(path):\n",
    "    img = read_img_bgr(path)\n",
    "    face = face_align(img)\n",
    "    if face is None:\n",
    "        return None\n",
    "    return embed_face_tensor(face)\n",
    "\n",
    "def cosine_similarity(a, b, eps=1e-8):\n",
    "    a = a / (np.linalg.norm(a) + eps)\n",
    "    b = b / (np.linalg.norm(b) + eps)\n",
    "    return float(np.dot(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f214ea57-8ef2-4e4b-a146-d982dfcb3fc9",
   "metadata": {},
   "source": [
    "#### Analisis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7797bbf-b50e-4828-8bc2-ca91481f71c8",
   "metadata": {},
   "source": [
    "File utils_facenet.py berisi seluruh utilitas inti yang digunakan untuk membaca gambar, mendeteksi wajah, melakukan alignment, dan menghasilkan embedding wajah menggunakan model FaceNet berbasis InceptionResnetV1. Script dimulai dengan memilih device (“cuda” jika GPU tersedia, jika tidak menggunakan CPU) sehingga sistem dapat bekerja optimal di berbagai lingkungan. Untuk proses deteksi dan alignment, script menggunakan MTCNN, yang bertugas mencari wajah dalam gambar, memotong area wajah, dan menormalkannya ke ukuran 160×160. Selanjutnya, model InceptionResnetV1 dengan pretrained vggface2 dipakai sebagai embedder yang menghasilkan vektor embedding berdimensi 512, yang menjadi representasi numerik unik untuk setiap wajah.\n",
    "\n",
    "Fungsi read_img_bgr() menggunakan OpenCV untuk membaca gambar dalam format BGR, sedangkan bgr_to_pil() mengkonversinya menjadi PIL RGB agar bisa diproses MTCNN. Fungsi face_align() menjalankan deteksi dan alignment wajah; jika wajah tidak ditemukan, fungsi mengembalikan None, yang mencegah error saat script lain memanggil embedding. Fungsi embed_face_tensor() menerima tensor wajah ter-align, menjalankannya melalui model embedder, lalu mengembalikan array numpy 512 dimensi. Fungsi utama embed_from_path() menggabungkan semua langkah: membaca gambar, mendeteksi wajah, melakukan alignment, hingga menghasilkan embedding akhir. Script juga menyediakan fungsi cosine_similarity() untuk menghitung kesamaan antara dua embedding, metode umum dalam face verification. Secara keseluruhan, file ini adalah inti dari seluruh pipeline pengenalan wajah karena menyediakan deteksi, preprocessing, dan ekstraksi fitur yang konsisten untuk digunakan pada KNN, SVM, maupun verifikasi berbasis jarak."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7755a83-58dd-4712-8c6e-752a7949f2c9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### verify_cli.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0106a8f-2077-442a-bf08-b87442d088ba",
   "metadata": {},
   "source": [
    "import argparse\n",
    "from utils_facenet import embed_from_path, cosine_similarity\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"img1\")\n",
    "parser.add_argument(\"img2\")\n",
    "parser.add_argument(\"--th\", type=float, default=0.85)\n",
    "args = parser.parse_args()\n",
    "\n",
    "e1 = embed_from_path(args.img1)\n",
    "e2 = embed_from_path(args.img2)\n",
    "\n",
    "if e1 is None or e2 is None:\n",
    "    print(\"❌ Wajah tidak terdeteksi.\")\n",
    "else:\n",
    "    sim = cosine_similarity(e1, e2)\n",
    "    print(f\"Similarity = {sim:.4f}\")\n",
    "    print(\"MATCH\" if sim >= args.th else \"NO MATCH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cfcf2a-5e69-46ee-8356-ee30066218de",
   "metadata": {},
   "source": [
    "#### Analisis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaac03a-595d-44c1-8610-bd092d748346",
   "metadata": {},
   "source": [
    "Script verify_cli.py berfungsi sebagai alat verifikasi wajah berbasis command-line yang membandingkan dua gambar dan menentukan apakah keduanya merupakan wajah orang yang sama. Program menggunakan argparse untuk menerima dua path gambar serta threshold kesamaan opsional (--th) dengan nilai default 0.85. Dua embedding wajah dihasilkan melalui fungsi embed_from_path() dari utils_facenet.py. Jika salah satu gambar tidak mengandung wajah yang berhasil dideteksi oleh MTCNN, script langsung menampilkan pesan error agar proses verifikasi tidak menghasilkan keputusan keliru.\n",
    "Ketika kedua wajah berhasil diekstraksi, script menghitung skor kemiripan menggunakan cosine similarity, sebuah metrik yang umum digunakan dalam sistem FaceNet karena dapat mengukur jarak angular antara dua vektor embedding. Hasil similarity dicetak dengan presisi empat desimal untuk transparansi. Setelah itu, script membandingkan nilai similarity tersebut dengan threshold. Jika similarity lebih besar atau sama dengan threshold, wajah dianggap MATCH (orang yang sama); jika lebih rendah, dianggap NO MATCH. Dengan desain yang sederhana namun efektif, script ini sangat cocok untuk membangun fitur verifikasi wajah mandiri atau proses uji cepat antara dua gambar tanpa melibatkan model klasifikasi seperti SVM atau KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc65d2a-23d8-46ef-b680-f390e89fbdbe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### verify_pair.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd37880-5992-421a-8aca-04bf4ef7fead",
   "metadata": {},
   "source": [
    "from utils_facenet import embed_from_path, cosine_similarity\n",
    "\n",
    "img1 =  \"samples/iin_test.jpeg\"    # ganti sesuai nama file kamu\n",
    "img2 = \"samples/ami_test.jpeg\"   # ganti sesuai nama file kamu\n",
    "\n",
    "emb1 = embed_from_path(img1)\n",
    "emb2 = embed_from_path(img2)\n",
    "\n",
    "if emb1 is None or emb2 is None:\n",
    "    print(\"Wajah tidak terdeteksi pada salah satu gambar.\")\n",
    "else:\n",
    "    sim = cosine_similarity(emb1, emb2)\n",
    "    print(\"Cosine similarity:\", sim)\n",
    "\n",
    "    threshold = 0.85\n",
    "    print(\"Match?\", \"YA\" if sim >= threshold else \"TIDAK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4daa41d0-2b12-435f-97a4-b73f56ed3eb2",
   "metadata": {},
   "source": [
    "#### Analisis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d57eaf1-4d82-4c3b-a254-bb1fd58865d6",
   "metadata": {},
   "source": [
    "Script verify_pair.py merupakan alat sederhana untuk melakukan verifikasi wajah dengan membandingkan dua gambar secara langsung tanpa menggunakan command-line argument seperti pada verify_cli.py. Program ini secara eksplisit mendefinisikan dua path gambar (img1 dan img2), kemudian menghasilkan embedding masing-masing gambar menggunakan fungsi embed_from_path() dari utils_facenet.py. Jika salah satu gambar gagal mendeteksi wajah, program segera menghentikan proses dan menampilkan peringatan.\n",
    "Ketika kedua embedding berhasil dihasilkan, script menghitung nilai kesamaan menggunakan cosine similarity, metode yang sangat umum dalam sistem FaceNet untuk mengukur kedekatan dua embedding wajah. Nilai similarity dicetak sehingga pengguna dapat melihat seberapa mirip kedua wajah tersebut dalam bentuk angka. Setelah itu, nilai similarity dibandingkan dengan threshold 0.85, yang menjadi batas apakah dua wajah dianggap identik atau tidak. Jika similarity lebih tinggi atau sama dengan threshold, program menampilkan “YA” sebagai indikator kecocokan, jika tidak maka “TIDAK”.\n",
    "Script ini sangat cocok untuk pengujian cepat, demonstrasi hasil embedding, dan eksperimen threshold karena sederhana, langsung, dan tidak memerlukan input tambahan. Ini juga berguna sebagai langkah debugging awal sebelum mengintegrasikan sistem verifikasi ke aplikasi yang lebih besar."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
